{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "rXHJLPGJ9vJ1",
        "TuXWvbnBCRqO",
        "ams1JybALBMD",
        "UwO9Z_rqlW5G"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMl7kYsDMXuEGQsa07N8f21",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tasty-orange/ARN-labs/blob/main/ARN_PW3_PT1_Piemontesi_Trueb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practical Work 3 ARN - G.Piemontesi & G.Trueb\n",
        "\n",
        "## Première expérience : Classification « awake » / « asleep »\n",
        "\n",
        "Dans cette expérience, nous allons classifier les états « awake » (éveillé) et « asleep » (endormi) des souris en regroupant les phases n-rem et rem sous « asleep ». L'objectif est de créer un modèle MLP pour prédire ces deux états à partir des données EEG des souris. Nous évaluerons les performances du modèle à l'aide de la perte d'entraînement, de la validation, de la matrice de confusion et du F1-score."
      ],
      "metadata": {
        "id": "biJ9EZDx3tHS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import des packages/dépendances\n",
        "\n"
      ],
      "metadata": {
        "id": "JrqAJN7V5ISP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dense\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "BctSd1yH3taM"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import des données des souris"
      ],
      "metadata": {
        "id": "rXHJLPGJ9vJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chargement des données d'entraînement\n",
        "mice_eeg_1 = pd.read_csv('EEG_mouse_data_1.csv')\n",
        "mice_eeg_2 = pd.read_csv('EEG_mouse_data_2.csv')\n",
        "\n",
        "# Fusion des deux jeux de données d'entraînement\n",
        "data_training = pd.concat([mice_eeg_1, mice_eeg_2])"
      ],
      "metadata": {
        "id": "_RhJdXs-8QzP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "cbf1ddcc-350e-452a-efcb-e71d8dc3bc15"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'EEG_mouse_data_1.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-7044bff814ec>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Chargement des données d'entraînement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmice_eeg_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'EEG_mouse_data_1.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmice_eeg_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'EEG_mouse_data_2.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Fusion des deux jeux de données d'entraînement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'EEG_mouse_data_1.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Preprocessing et normalisation des données"
      ],
      "metadata": {
        "id": "TuXWvbnBCRqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comme on peut le voir dans le diagramme en barres ci-dessous, nous avons trois états pour le sommeil des souris, et nous voulons n'en avoir que deux : 'awake' et 'asleep'."
      ],
      "metadata": {
        "id": "hoiVIENXCpbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_training.state.value_counts().plot(kind='bar', cmap='Dark2')\n",
        "plt.title('Total Occurences per State')\n",
        "plt.xticks(rotation=0)\n",
        "plt.ylabel('Count')\n",
        "plt.xlabel('State');"
      ],
      "metadata": {
        "id": "Er0KfdHrA4bT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modification du dataset pour fusionner les états 'n' et 'r' en un seul pour 'asleep', afin de n'avoir plus que les états 'awake' et 'asleep'."
      ],
      "metadata": {
        "id": "ngFGj7CeDH4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modifier la variable cible 'state' pour n'avoir que deux classes : 'awake' et 'asleep'\n",
        "data_training['state'] = data_training['state'].replace({'w': 'awake', 'r': 'asleep', 'n': 'asleep'})\n",
        "data_training.state.value_counts().plot(kind='bar', cmap='Dark2')\n",
        "plt.title('Total Occurences per State')\n",
        "plt.xticks(rotation=0)\n",
        "plt.ylabel('Count')\n",
        "plt.xlabel('State');"
      ],
      "metadata": {
        "id": "SmkhECn-Bn-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Séparer les caractéristiques et la variable cible\n",
        "input_data = data_training.drop('state', axis=1).values\n",
        "output_data = data_training['state'].values\n",
        "\n",
        "# Garder seulement les 25 premières caractéristiques\n",
        "input_data = input_data[:, :25]\n",
        "\n",
        "# Normaliser les données d'entrée\n",
        "scaler = StandardScaler()\n",
        "input_data = scaler.fit_transform(input_data)\n",
        "\n",
        "# Encoder la variable cible\n",
        "encoder = LabelEncoder()\n",
        "output_data = encoder.fit_transform(output_data)\n",
        "\n",
        "# Définir KFold\n",
        "kf = KFold(n_splits=3, shuffle=True, random_state=1)"
      ],
      "metadata": {
        "id": "ZvZ4EYh1EL7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creation du modèle MLP\n"
      ],
      "metadata": {
        "id": "Em8fWEwTHGpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create():\n",
        "    model = Sequential([\n",
        "        # Entrée avec les 25 caractéristiques\n",
        "        Input(shape=(25,)),\n",
        "\n",
        "        # Première couche cachée avec régularisation L2\n",
        "        Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "\n",
        "        # Deuxième couche cachée avec régularisation L2\n",
        "        Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "\n",
        "        # Dropout pour éviter le surapprentissage, 30% des neurones sont mis à zéro durant l'entraînement\n",
        "        Dropout(0.3),\n",
        "\n",
        "        # Couche de sortie\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    # Compiler le modèle avec l'optimiseur Adam\n",
        "    model.compile(\n",
        "        loss='binary_crossentropy',\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Afficher le modèle\n",
        "model = create()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "cn8oSPVmEjIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entraînement du modèle"
      ],
      "metadata": {
        "id": "ams1JybALBMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stockage des métriques\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "f1_scores = []\n",
        "conf_matrices = []\n",
        "\n",
        "# Entraînement du modèle avec validation croisée\n",
        "for fold, (train_index, val_index) in enumerate(kf.split(input_data)):\n",
        "    X_train, X_val = input_data[train_index], input_data[val_index]\n",
        "    y_train, y_val = output_data[train_index], output_data[val_index]\n",
        "\n",
        "    model = create()\n",
        "\n",
        "    history = model.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val))\n",
        "\n",
        "    # Stocker les pertes\n",
        "    train_losses.append(history.history['loss'])\n",
        "    val_losses.append(history.history['val_loss'])\n",
        "\n",
        "    # Prédictions sur l'ensemble de validation\n",
        "    y_pred = model.predict(X_val)\n",
        "    y_pred = (y_pred > 0.5).astype(int)\n",
        "\n",
        "    # Matrice de confusion\n",
        "    cm = confusion_matrix(y_val, y_pred)\n",
        "    conf_matrices.append(cm)\n",
        "\n",
        "    # Calcul du F1-score\n",
        "    f1 = f1_score(y_val, y_pred)\n",
        "    f1_scores.append(f1)"
      ],
      "metadata": {
        "id": "0rE7nHq6Lptm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Évaluation du modèle"
      ],
      "metadata": {
        "id": "UwO9Z_rqlW5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Affichage des courbes de perte séparément par fold\n",
        "for fold in range(3):\n",
        "    # Courbe de perte\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(train_losses[fold], label='Training Loss', color='blue')\n",
        "    plt.plot(val_losses[fold], label='Validation Loss', color='red', linestyle='dashed')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title(f'Training vs Validation Loss - Fold {fold+1}')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.tight_layout()  # Ajuste les espaces entre les graphiques pour éviter les chevauchements\n",
        "    plt.show()\n",
        "\n",
        "    # Matrice de confusion\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    sns.heatmap(conf_matrices[fold], annot=True, fmt='d', cmap='Blues', xticklabels=['Asleep', 'Awake'], yticklabels=['Asleep', 'Awake'])\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title(f'Confusion Matrix - Fold {fold+1}')\n",
        "    plt.tight_layout()  # Ajoute de l'espace entre la matrice et les axes\n",
        "    plt.show()\n",
        "\n",
        "# Affichage du F1-score moyen final\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "print(f'\\nF1-score moyen final : {mean_f1:.4f}')\n"
      ],
      "metadata": {
        "id": "Y5K90WnCRoJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Évaluation du modèle sur le jeu de données de test"
      ],
      "metadata": {
        "id": "ra8gsFPWmVU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chargement des données de test\n",
        "data_test = pd.read_csv('EEG_mouse_data_test.csv')"
      ],
      "metadata": {
        "id": "Zc38L7pgmSqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prendre les 25 premières caractéristiques de l'entraînement\n",
        "columns_used_for_training = data_training.drop('state', axis=1).columns[:25]\n",
        "\n",
        "# Sélectionner uniquement ces 25 colonnes dans les données de test\n",
        "data_test_selected = data_test[columns_used_for_training]\n",
        "\n",
        "# Normaliser les données de test avec le même scaler\n",
        "X_test_final_normalized = scaler.transform(data_test_selected)\n",
        "\n",
        "# Prédiction des classes pour les données de test\n",
        "y_pred_final = model.predict(X_test_final_normalized)\n",
        "\n",
        "# Créer un DataFrame pour les prédictions et les enregistrer dans un fichier CSV\n",
        "predictions_df = pd.DataFrame(predicted_classes, columns=['Predicted_Class'])\n",
        "\n",
        "# Enregistrer dans un fichier CSV\n",
        "predictions_df.to_csv('predictions_test.csv', index=False)\n",
        "\n",
        "# Afficher le message de confirmation\n",
        "print(\"Les prédictions ont été enregistrées dans 'predictions_test.csv'.\")\n",
        "\n",
        "# Plot en barres de la distribution des classes prédites\n",
        "plt.figure(figsize=(8, 6))\n",
        "predictions_df['Predicted_Class'].value_counts().plot(kind='bar', color='darkgreen')\n",
        "plt.title('Distribution des Classes Prédites dans les Données de Test')\n",
        "plt.xlabel('Classe Prédite')\n",
        "plt.ylabel('Nombre d\\'Occurrences')\n",
        "plt.xticks(rotation=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IILCh5LsmU_B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}