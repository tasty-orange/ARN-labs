{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fzEzTbRDHsF6"
   },
   "source": [
    "# Delta Rule\n",
    "The Delta Rule is a gradient descent approximator that can be used to find the weight values of a Perceptron. The Delta Rule minimizes an error function (tipically $E=\\frac{1}{2}(y - t)^{2}$) by adapting the weight connections in small steps. The step length is defined by the learning rate $\\alpha$. In this notebook you will explore the classification capabilities of a single Perceptron by using the delta rule. You will start by setting the connection weights by hand for a simple problem, and then you will apply the delta rule for the same problem, and others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9EpGLdcQHsF_"
   },
   "source": [
    "## Loading the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_jPO1_dAHsF_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "from ipywidgets import interact, widgets\n",
    "\n",
    "from matplotlib import animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Snlhqm3XHsGB"
   },
   "source": [
    "## Loading the Perceptron code\n",
    "In order to the make this nothebook smaller, some of the functions (activation functions, and some of the code allowing the visualization of the results) was implemented in a separate python file. You are free to open it if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color=\"red\">**For it to work on Colab, make sure to have uploaded the percpetron.py file in your environment**</font>"
   ],
   "metadata": {
    "id": "1REfiudwTNzf"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NkrOMATjHsGB",
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import perceptron as pt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fhR5-SrKHsGC"
   },
   "source": [
    "## The Dataset\n",
    "The following script allows you to create a 2D dataset by using the mouse. Pressing 'b' adds points belonging to class A (blue), and pressing 'r' adds points belonging to class B (red). You can create as many points as you desire. The final dataset will contain hence three values per point: x coordinate (-1 ≤ x ≤ 1), y coordinate (-1 ≤ y ≤ 1) and the class ∈ {1,-1}."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install ipympl"
   ],
   "metadata": {
    "id": "XmxKxU1oI539"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color=\"red\">**For it to work on Colab, you will need to reload your session (Exécution -> redémarrer la session)**</font>"
   ],
   "metadata": {
    "id": "LJkqhl0_TEYf"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": false,
    "id": "zZ7IfgvoHsGC",
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "%matplotlib widget\n",
    "\n",
    "from google.colab import output\n",
    "output.enable_custom_widget_manager()\n",
    "\n",
    "fig = pl.figure(figsize=(6,6))\n",
    "pl.title(\"Input Dataset\")\n",
    "pl.xlim((-1.2,1.2))\n",
    "pl.ylim((-1.2,1.2))\n",
    "\n",
    "dataset = []\n",
    "\n",
    "def on_press(event):\n",
    "    if event.key == 'b':\n",
    "        dataset.append((event.xdata, event.ydata, -1))\n",
    "        pl.scatter(event.xdata, event.ydata, color='blue')\n",
    "        pl.draw()\n",
    "    elif event.key == 'r':\n",
    "        dataset.append((event.xdata, event.ydata, 1))\n",
    "        pl.scatter(event.xdata, event.ydata, color='red')\n",
    "        pl.draw()\n",
    "\n",
    "# Attach the event handler\n",
    "fig.canvas.mpl_connect('key_press_event', on_press);"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O1qw60LAHsGE"
   },
   "source": [
    "This is the dataset you just created. Check that there are no NaNs in the third column. Create once again the dataset if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ykxraw3eHsGE"
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7cHeM4L4HsGF"
   },
   "source": [
    "## Finding the weights by hand\n",
    "In this section you should try to find the set of weights that allows a Perceptron to separate the two classes you previously defined. Use the sliders to modify the value of each one of the connections and the bias of the Perceptron while trying to separate the two classes (blue and red). The curve on the right represents the classification error (MSE). If the modifications you provide improve the classification, you should see the error decreasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NqmRPhkFHsGG"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plotter = pt.PerceptronPlotter2D(data=np.asarray(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pz77OkR3HsGG"
   },
   "outputs": [],
   "source": [
    "fig.clf()\n",
    "_= interact(plotter.plot_interactive, **plotter.controls)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice that Sigmoid outputs value between 0 and 1 and that our classes have been defined as -1 and 1. Is it a problem? Do you have the same problem with hyperbolic tangent?"
   ],
   "metadata": {
    "id": "AL4ynlTILR2j"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IlFeGn7hHsGG"
   },
   "source": [
    "## The Delta Rule\n",
    "In the following step we propose to solve the classification problem you defined by using the delta-rule algorithm. Look at the code in compute_delta_w and try to understand it."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "mfuiIt4cHsGH"
   },
   "source": [
    "            ______________\n",
    "           /              \\\n",
    "x __w_x__ j                l\n",
    "  _______ | f_act(I.W + b) |------ output\n",
    "y   w_y   l                j\n",
    "           \\______________/\n",
    "Where:\n",
    "x = input x\n",
    "y = input y\n",
    "b = bias\n",
    "f_act = activation function\n",
    "I = vector of inputs\n",
    "W = vector of weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-89IekkHsGH"
   },
   "source": [
    "$$ neta = (x * w\\_x) + (y * w\\_y) + b$$\n",
    "$$ output = f\\_act(neta) $$\n",
    "$$ \\Delta w\\_x = \\alpha * (target - output) * f\\_act'(neta) * x $$\n",
    "$$ \\Delta w\\_y = \\alpha * (target - output) * f\\_act'(neta) * y $$\n",
    "$$ \\Delta b = \\alpha * (target - output) * f\\_act'(neta) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hpyy-kQFHsGH"
   },
   "outputs": [],
   "source": [
    "def compute_delta_w(inputs, weights, bias, targets, alpha, activation_function):\n",
    "    neta = np.dot(inputs, weights) + bias\n",
    "    output, d_output = activation_function(neta)\n",
    "    error = targets - output\n",
    "    d_w_x = alpha * error * d_output * inputs[:,0]\n",
    "    d_w_y = alpha * error * d_output * inputs[:,1]\n",
    "    d_b = alpha * error * d_output\n",
    "    return [d_w_x, d_w_y, d_b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PR3U7G4EHsGI"
   },
   "source": [
    "## Batch learning\n",
    "When you launch the cell, the weights and the bias are initialized at random, and the algorithm perform some iterations (NUMBER_OF_EPOCHS) doing the following:\n",
    "+  for each point in the dataset, compute the modifications ( Δw ) to be done at each parameter in order to minimize the error function\n",
    "+ sum up all the modifications -> batch policy\n",
    "+ modify the weights and bias of the perceptron\n",
    "\n",
    "The cell records the effects of the modifications performed in a video. Therefore, you can visualize the learning process afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "id": "OhNZY6JkHsGI"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "inputs = np.asarray(dataset)[:,0:2]\n",
    "targets = np.asarray(dataset)[:,2]\n",
    "weights = np.random.normal(size=2)\n",
    "bias = np.random.normal(size=1)\n",
    "activation_function = pt.htan\n",
    "\n",
    "ALPHA = 0.1\n",
    "NUMBER_OF_EPOCHS = 30\n",
    "\n",
    "fig = pl.figure(figsize=(12, 4))\n",
    "plotter = pt.PerceptronPlotter2D(data=np.asarray(dataset))\n",
    "plotter.init_animation()\n",
    "\n",
    "def run_epoch_batch(i, alpha, inputs, weights, bias, targets, activation_function):\n",
    "    d_w_x, d_w_y, d_b = compute_delta_w(inputs, weights, bias, targets, ALPHA, activation_function)\n",
    "    weights += np.array([np.sum(d_w_x), np.sum(d_w_y)])\n",
    "    bias += np.sum(d_b)\n",
    "\n",
    "    return plotter.data2animation(i, inputs, weights, bias, targets, activation_function)\n",
    "\n",
    "SHOW_VIDEO = True       # change this flag if you are unable to see the video\n",
    "if SHOW_VIDEO:\n",
    "    anim = animation.FuncAnimation(fig, run_epoch_batch, fargs=(ALPHA, inputs, weights, bias, targets, activation_function), frames=NUMBER_OF_EPOCHS, interval=20, blit=True)\n",
    "    pt.display_animation(anim)\n",
    "else:\n",
    "    for i in np.arange(NUMBER_OF_EPOCHS):\n",
    "        run_epoch_batch(i, ALPHA, inputs, weights, bias, targets, activation_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "hLfPeVe_HsGJ"
   },
   "source": [
    "## Exercise\n",
    "You are free to modify the learning rate (ALPHA) and the number of iterations (NUMBER_OF_EPOCHS).\n",
    "\n",
    "Try different 2D classification problems and observe the behaviour of the algorithm in terms of:\n",
    "- Learning rate needed\n",
    "- Convergence speed\n",
    "- Oscillations\n",
    "\n",
    "Bare in mind that, in the current implementation, the parameters (weights and bias) are initialized randomly every time you launch the cell.\n",
    "\n",
    "Create dataset as shown and perform the following tests:\n",
    "\n",
    "1. What happens if the boundaries between both classes are well defined?\n",
    "![separable](https://drive.google.com/uc?id=1jctNojH56KXougUipA8fney25xwFeH8l)\n",
    "\n",
    "2. What happens if the classes overlap? What could you say about oscillations in the error signal?\n",
    "![overlapping](https://drive.google.com/uc?id=1pNjh1OQjJgQw_UTEzancv-xEnrKubTfl)\n",
    "\n",
    "3. What happens if it is not possible to separate the classes with a single line? What could you say about local minima?\n",
    "![non_separable](https://drive.google.com/uc?id=17QWBDNiw2TuY7EIoH1BoDzDc2YEIm__M)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
